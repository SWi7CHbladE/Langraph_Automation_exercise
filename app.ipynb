{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d59011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635db010",
   "metadata": {},
   "source": [
    "# 1. Define the state (memory passed between nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fc7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabf3de",
   "metadata": {},
   "source": [
    "# 2. Create an Ollama LLM wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2:3b\")  \n",
    "# You can use any model you pulled with ollama (e.g. \"mistral\", \"gemma:2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf27ba",
   "metadata": {},
   "source": [
    "# 3. Define graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f2441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_node(state: GraphState):\n",
    "    \"\"\"Takes a question and generates an answer using Ollama.\"\"\"\n",
    "    q = state[\"question\"]\n",
    "    response = llm.invoke(q)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "def print_node(state: GraphState):\n",
    "    \"\"\"Print the final answer.\"\"\"\n",
    "    print(\"Q:\", state[\"question\"])\n",
    "    print(\"A:\", state[\"answer\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456adb3",
   "metadata": {},
   "source": [
    "# 4. Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d9495a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fb049121580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "graph.add_node(\"print\", print_node)\n",
    "\n",
    "graph.set_entry_point(\"answer\")\n",
    "graph.add_edge(\"answer\", \"print\")\n",
    "graph.add_edge(\"print\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfdcf13",
   "metadata": {},
   "source": [
    "# 5. Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fa2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737b586",
   "metadata": {},
   "source": [
    "# 6. Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5cfb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is LangGraph and how is it different from LangChain?\n",
      "A: LangGraph and LangChain are both open-source Python libraries used for building natural language processing (NLP) pipelines. While they share some similarities, they have distinct design goals and use cases.\n",
      "\n",
      "**LangChain:**\n",
      "\n",
      "LangChain is a more general-purpose library that focuses on building modular, reusable NLP workflows. It aims to provide a flexible framework for combining different components of an NLP pipeline, such as text processing, entity recognition, sentiment analysis, and more. LangChain uses a plugin-based architecture, where users can develop custom components or use pre-built ones from the community.\n",
      "\n",
      "LangChain's primary benefits include:\n",
      "\n",
      "* High degree of customization\n",
      "* Modular design allows for easier maintenance and updates\n",
      "* Supports a wide range of NLP tasks\n",
      "\n",
      "However, LangChain can be overwhelming for beginners due to its flexibility and the need to write custom code.\n",
      "\n",
      "**LangGraph:**\n",
      "\n",
      "LangGraph is another Python library designed specifically for building NLP pipelines. Unlike LangChain, LangGraph focuses on simplicity, ease of use, and performance. It provides a high-level API for defining workflows that combine multiple NLP tasks into a single pipeline.\n",
      "\n",
      "LangGraph's primary benefits include:\n",
      "\n",
      "* Simpler and more intuitive API\n",
      "* Easier to use for beginners and experts alike\n",
      "* Optimized performance for large-scale NLP pipelines\n",
      "\n",
      "However, LangGraph might not offer the same level of customization as LangChain, which could be a drawback for more advanced users.\n",
      "\n",
      "**Key differences:**\n",
      "\n",
      "1. **Design philosophy:** LangChain is designed for flexibility and modularity, while LangGraph prioritizes simplicity and ease of use.\n",
      "2. **API complexity:** LangChain's API is more complex due to its plugin-based architecture, whereas LangGraph has a simpler, high-level API.\n",
      "3. **Customizability:** LangChain offers greater customization options through its plugin system, but this also requires more expertise. LangGraph is more straightforward and easier to use, but might not offer the same level of customization.\n",
      "\n",
      "In summary, if you need a flexible, modular framework for building complex NLP workflows, LangChain might be a better choice. However, if you prioritize simplicity, ease of use, and performance in your NLP pipelines, LangGraph could be an excellent option.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    inputs = {\"question\": \"What is LangGraph and how is it different from LangChain?\"}\n",
    "    app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e33840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
